---
date: 2023-08-18
author: Mojo Dojo
author_site: https://mojodojo.dev
author_image: https://mojodojo.dev/hero.png
feed: true
head:
  - [meta, { name: twitter:card , content: summary }]
  - [meta, { name: twitter:site , content: '@mojodojodev' }]
  - [meta, { name: twitter:title , content: This Week in Mojo }]
  - [meta, { name: twitter:description , content: "This week in Mojo with language updates, community content, and everything else related to Mojo" }]
  - [meta, { name: twitter:image , content: "https://mojodojo.dev/hero.png" }]
---

![Logo](/hero.png)

# This Week in Mojo 2023-08-18

## Official Content
- New blog post: [How MojoðŸ”¥ gets a 35,000x speedup over Python â€“ Part 1](https://www.modular.com/blog/how-mojo-gets-a-35-000x-speedup-over-python-part-1)

## Community Content
- Maxim made a blog post on a binary search tree implementation he's working on: [A high level introduction to FibyTree](https://mzaks.medium.com/a-high-level-introduction-to-fibytree-bd7f8775d815)

## Team Answers

### Small Binary Size for Embedded
In fullness of time Mojo will be very useful for this sort of use-case. We haven't done any work on code size directly, but a statically linked hello world program produces a ~100K `a.out` file on a linux system. Mojo supports inline asm, but it is pretty ugly to use right now, we'll improve that later.

There are a lot of analogs between embedded systems and GPU/accelerator programming btw, both want effectively-no-dependence runtimes.

- [2023-08-12 Chris Lattner](https://discord.com/channels/1087530497313357884/1139563087498842232/1139589228297199677)

### ONNX Runtime
we run benchmarks against ONNX Runtime, and in our tests, the Modular AI Engine is almost always faster than it. We may add these numbers to the public dashboard at https://performance.modular.com/ in the future.

- [2023-08-14 Alex Kirchhoff](https://discord.com/channels/1087530497313357884/1140700862524690632/1140733786414399608)
