{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "title: Benchmark\n",
                "categories: Benchmark\n",
                "usage: Pass in a closure that returns None as a parameter to benchmark its speed in nanoseconds\n",
                "---\n",
                "# Benchmark\n",
                "## Import"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from Benchmark import Benchmark"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## General Usage"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Loop through each number up to `n` and calculate the total in the fibonacci sequence:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "alias n = 35 "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Define the recursive version first:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "fn fib(n: Int) -> Int:\n",
                "    if n <= 1:\n",
                "       return n \n",
                "    else:\n",
                "       return fib(n-1) + fib(n-2)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To benchmark it, create a nested `fn` that takes no arguments and doesn't return anything, then pass it in as a parameter:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Nanoseconds: 50322420\n",
                        "Seconds: 0.05032242\n"
                    ]
                }
            ],
            "source": [
                "fn bench():\n",
                "    fn closure():\n",
                "        for i in range(n):\n",
                "            _ = fib(i)\n",
                "\n",
                "    let nanoseconds = Benchmark().run[closure]()\n",
                "    print(\"Nanoseconds:\", nanoseconds)\n",
                "    print(\"Seconds:\", Float64(nanoseconds) / 1e9)\n",
                "\n",
                "bench()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Define iterative version for comparison:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Nanoseconds iterative: 0\n"
                    ]
                }
            ],
            "source": [
                "fn fib_iterative(n: Int) -> Int:\n",
                "    var count = 0\n",
                "    var n1 = 0\n",
                "    var n2 = 1\n",
                "\n",
                "    while count < n:\n",
                "       let nth = n1 + n2\n",
                "       n1 = n2\n",
                "       n2 = nth\n",
                "       count += 1\n",
                "    return n1\n",
                "\n",
                "fn bench_iterative():\n",
                "    fn iterative_closure():\n",
                "        for i in range(n):\n",
                "            _ = fib_iterative(i)\n",
                "\n",
                "    let iterative = Benchmark().run[iterative_closure]()\n",
                "    print(\"Nanoseconds iterative:\", iterative)\n",
                "\n",
                "bench_iterative()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Notice that the compiler has optimized away everything, LLVM can change an iterative loop to a constant value if all the inputs are known at compile time through `constant folding`, or if the value isn't actually used for anything with `Dead Code Elimination` both of which could be occurring here.\n",
                "\n",
                "There is a lot going on under the hood, and so you should always test your assumptions with benchmarks, especially if you're adding complexity because you _think_ it will improve performance, [which often isn't the case](https://vimeo.com/649009599)."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Max iters\n",
                "Set max iterations and a 1s max total duration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0 warmup iters, 4 max iters, 0ns min time, 1_000_000_000ns max time\n",
                        "sleeping 300,000ns\n",
                        "sleeping 300,000ns\n",
                        "sleeping 300,000ns\n",
                        "sleeping 300,000ns\n",
                        "sleeping 300,000ns\n",
                        "sleeping 300,000ns\n",
                        "average time 363769\n"
                    ]
                }
            ],
            "source": [
                "from Time import sleep\n",
                "\n",
                "fn bench_args():\n",
                "    fn sleeper():\n",
                "        print(\"sleeping 300,000ns\")\n",
                "        sleep(3e-4)\n",
                "    \n",
                "    print(\"0 warmup iters, 4 max iters, 0ns min time, 1_000_000_000ns max time\")\n",
                "    let nanoseconds = Benchmark(0, 5, 0, 1_000_000_000).run[sleeper]()\n",
                "    print(\"average time\", nanoseconds)\n",
                "\n",
                "bench_args()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Note there is some extra logic inside `Benchmark` to help improve accuracy, so here it actually runs 6 iterations"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Max Duration\n",
                "Limit the max running time, so it will never run over 0.001 seconds and will not hit the max iters of 5:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "0 warmup iters, 5 max iters, 0 min time, 1_000_000ns max time\n",
                        "sleeping 300,000ns\n",
                        "sleeping 300,000ns\n",
                        "sleeping 300,000ns\n",
                        "average time 364582\n"
                    ]
                }
            ],
            "source": [
                "fn bench_args_2():\n",
                "    fn sleeper():\n",
                "        print(\"sleeping 300,000ns\")\n",
                "        sleep(3e-4)\n",
                "    \n",
                "    print(\"\\n0 warmup iters, 5 max iters, 0 min time, 1_000_000ns max time\")\n",
                "    let nanoseconds = Benchmark(0, 5, 0, 1_000_000).run[sleeper]()\n",
                "    print(\"average time\", nanoseconds)\n",
                "\n",
                "bench_args_2()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Min Duration\n",
                "Try with a minimum of 3 million nanoseconds, so it ignores the max iterations and runs 5 normal runs:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "sleeping 300,000ns\n",
                        "sleeping 300,000ns\n",
                        "sleeping 300,000ns\n",
                        "sleeping 300,000ns\n",
                        "sleeping 300,000ns\n",
                        "sleeping 300,000ns\n",
                        "sleeping 300,000ns\n",
                        "sleeping 300,000ns\n",
                        "average time 366545\n"
                    ]
                }
            ],
            "source": [
                "fn bench_args():\n",
                "    fn sleeper():\n",
                "        print(\"sleeping 300,000ns\")\n",
                "        sleep(3e-4)\n",
                "\n",
                "    let nanoseconds = Benchmark(0, 2, 1_500_000, 1_000_000_000).run[sleeper]()\n",
                "    print(\"average time\", nanoseconds)\n",
                "\n",
                "bench_args()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Warmup\n",
                "You should always have some warmup iterations, there is some extra logic for more accurate results so it won't run exactly what you specify:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "sleeping 300,000ns\n",
                        "sleeping 300,000ns\n",
                        "sleeping 300,000ns\n",
                        "sleeping 300,000ns\n",
                        "sleeping 300,000ns\n",
                        "sleeping 300,000ns\n",
                        "average time 364094\n"
                    ]
                }
            ],
            "source": [
                "fn bench_args():\n",
                "    fn sleeper():\n",
                "        print(\"sleeping 300,000ns\")\n",
                "        sleep(3e-4)\n",
                "\n",
                "    let nanoseconds = Benchmark(1, 2, 0, 1_000_000_000).run[sleeper]()\n",
                "    print(\"average time\", nanoseconds)\n",
                "\n",
                "bench_args()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<CommentService />"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Mojo",
            "language": "mojo",
            "name": "mojo-jupyter-kernel"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "mojo"
            },
            "file_extension": ".mojo",
            "mimetype": "text/x-mojo",
            "name": "mojo"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
